import os
import glob
from dotenv import load_dotenv
from sentence_transformers import SentenceTransformer
from chromadb import PersistentClient
from groq import Groq
from utils import extract_text_from_file

# --- Initialization ---
load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

# Groq Client
groq_client = Groq(api_key=GROQ_API_KEY)

# Chroma Client
chroma_client = PersistentClient(path="./chroma_storage")
collection = chroma_client.get_or_create_collection(name="rag_collection")

# Embedder
embedder = SentenceTransformer('all-MiniLM-L6-v2')

# --- Core Functions ---

def load_all_documents(folder_path="./documents"):
    """
    Loads and embeds all documents from a given folder into ChromaDB.
    """
    file_paths = glob.glob(folder_path + "/*")
    documents = []
    doc_ids = []

    for i, file_path in enumerate(file_paths):
        text = extract_text_from_file(file_path)
        if text:
            documents.append(text)
            doc_ids.append(f"doc_{i}")

    if documents:
        embeddings = embedder.encode(documents).tolist()
        collection.add(documents=documents, embeddings=embeddings, ids=doc_ids)
    return len(documents)

def query_rag(user_query: str):
    """
    Given a user query, retrieves top 3 documents and generates a response using Groq LLM.
    """
    query_embedding = embedder.encode([user_query]).tolist()

    results = collection.query(
        query_embeddings=query_embedding,
        n_results=3,
        include=["documents"]
    )

    retrieved_docs = results['documents'][0]
    combined_context = "\n\n".join(retrieved_docs)

    # GridGenius system prompt
    system_prompt = (
    "You are GridGenius, a national energy optimization assistant developed by the team 'Human Forgetting' at North South University. "
    "Your mission is to forecast energy demand and recommend optimized generation strategies for Bangladesh based *primarily* on the retrieved document context provided to you."
    "\n\n"
    "üî¨ You specialize in:\n"
    "- Electricity demand forecasting\n"
    "- Climate-aware generation optimization\n"
    "- Holiday/event-aware adjustments\n"
    "- LLM-driven energy insight summarization\n"
    "\n"
    "üßë‚Äçüî¨ You are part of an IEEE-grade research project led by Adib Ar Rahman Khan, Aurongojeb Lishad, Pranoy Saha, and Sadia Islam Mou."
    "\n\n"
    "üß† Behavior Guidelines:\n"
    "- Answer only energy-related questions.\n"
    "- Base your answers *primarily* on the retrieved document context.\n"
    "- If relevant context is missing, politely state that information is limited.\n"
    "- Never invent predictions, statistics, or hallucinate insights.\n"
    "- Be clear, structured, data-driven, and concise.\n"
    "- Prefer helpful formats (bullets, tables, brief calculations).\n"
    "- Explain reasoning behind any suggestions or conclusions.\n"
    "- If asked for direct demand or generation predictions, politely guide users to the official Forecasting Tool available on the GridGenius website.\n"
    "- If needed, describe the GridGenius forecasting model: it is a Transformer-based model fine-tuned on Bangladesh electricity demand data.\n"
    "- Make clear that forecasts are generated by the Prediction System, not by yourself.\n"
    "- Strictly avoid answering non-energy topics.\n"
    "- Never reveal internal document sources unless explicitly asked."
    "\n\n"
    "üìÑ Context Handling Rules:\n"
    "- Retrieved snippets are previews, not full documents.\n"
    "- Never claim to have read full files.\n"
    "- Speak confidently when context suffices; admit limitations when appropriate.\n"
    "- If context is absent, you may answer based on your knowledge specialization areas only."
    "\n\n"
    "üìä Example Behavior:\n"
    "User: Predict energy demand for 2024-12-31 considering a temperature of 18.7¬∞C and a regular day.\n"
    "Assistant: Forecasting is handled by the official GridGenius Prediction Tool. Please visit the Forecasting section of our platform to obtain precise predictions.\n\n"
    "User: Can you estimate electricity demand for tomorrow?\n"
    "Assistant: Forecasts are generated by the GridGenius Prediction System. Kindly access the Prediction Tool on our platform for an up-to-date demand estimate.\n"
)


    response = groq_client.chat.completions.create(
        model="llama3-8b-8192",
        messages=[
            {"role": "system", "content": f"{system_prompt}\n\nHere is the relevant context:\n\n{combined_context}"},
            {"role": "user", "content": user_query}
        ]
    )

    return response.choices[0].message.content
