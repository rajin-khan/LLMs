<div align="center">

<img src="https://twimlai.com/wp-content/uploads/llms_800x800.png" alt="LLM Fine-Tuning Banner" height="280">

# LLM Repository

##### This repo will serve as a hands-on deep dive into fine-tuning large language models, as part of my self-taught LLM journey.

---

## 📚 About This Project

This repository will start off with the core projects under my [Machine Learning Series](https://github.com/rajin-khan/self-machine-learning), where I document my exploration of foundational and advanced concepts in working with large language models.

In this particular repo, initially, I'll go all-in on **fine-tuning LLMs**—not just the how, but also the why. I'll explore cutting-edge techniques like quantization, LoRA, QLoRA, and parameter-efficient fine-tuning using real-world models like LLaMA 2 and Google's Gemma.

Whether you're just getting started or prepping for an AI job interview, this repo will distill theory, code, and practice into one learning capsule.

---

## 🔍 Topics Explored

| **Category**                 | **Concepts**                                                                 |
|-----------------------------|------------------------------------------------------------------------------|
| **📐 Theory**               | Full vs. half precision, quantization, calibration, LoRA, QLoRA              |
| **⚙️ Techniques**           | Post-training quantization, quantization-aware training (QAT)               |
| **🧠 LLM Models**           | LLaMA 2, Gemma, GPT-3.5/4 (theoretical references)                         |
| **🧪 Experimentation**       | Custom dataset fine-tuning, inference optimization                          |

---

</div>

## 📂 Structure

```plaintext
📂 llm-finetuning
├── 📁 notebooks/         # Practical walkthroughs and colab-ready experiments
├── 📁 theory/            # In-depth explanations of fine-tuning and optimization concepts
├── 📁 examples/          # End-to-end mini projects and applications
├── 📄 README.md          # This file
```
<div align="center">
---

## 🛠️ Tools & Technologies

| Category             | Stack                                                                                     |
|----------------------|--------------------------------------------------------------------------------------------|
| Languages            | ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white) |
| Model Libraries      | ![HuggingFace](https://img.shields.io/badge/HuggingFace-FFD21F?style=for-the-badge&logo=huggingface&logoColor=black) |
| Visualization        | ![Matplotlib](https://img.shields.io/badge/Matplotlib-11557C?style=for-the-badge&logo=python&logoColor=white) |
| IDEs & Notebooks     | ![VS Code](https://img.shields.io/badge/VS_Code-007ACC?style=for-the-badge&logo=visual-studio-code&logoColor=white) ![Jupyter](https://img.shields.io/badge/Jupyter-F37626?style=for-the-badge&logo=jupyter&logoColor=white) |

---

## 🚀 Learning Goals

- Understand the mathematical and implementation details behind model **quantization**.
- Practice **parameter-efficient fine-tuning (PEFT)** using LoRA and QLoRA.
- Train LLMs on **custom datasets** and optimize them for inference.
- Prepare for technical interviews in the **Generative AI** domain.

---

## 📈 Progress Tracker

| Topic                        | Status          | Notes |
|-----------------------------|------------------|-------|
| Quantization                | 🔄 In Progress     | Includes theory + notebook  |
| Calibration Techniques      | ⏳ Not Started     | Symmetric vs. Asymmetric    |
| LoRA / QLoRA                | ⏳ Not Started   | Working on math intuition   |
| End-to-End Fine-Tuning      | ⏳ Not Started   | Gemma + LLaMA 2 on HF       |
| Inference Optimization      | ⏳ Not Started   | On-device deployment plans  |

---

## 🎥 Reference Video

This project is built on insights from this amazing crash course:  
[![YouTube](https://img.shields.io/badge/Watch%20Crash%20Course-Fine--Tuning%20LLMs-red?style=for-the-badge&logo=youtube&logoColor=white)](https://www.youtube.com/watch?v=iOdFUJiB0Zc)

---

[![Dev Quotes](https://quotes-github-readme.vercel.app/api?border=truel&type=horizontal&theme=dark)](https://github.com/piyushsuthar/github-readme-quotes)

</div>
